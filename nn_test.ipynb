{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './python_lib')\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import graph_gen\n",
    "import model\n",
    "import imp\n",
    "imp.reload(model)\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class myLayer(nn.Linear):\n",
    "    def __init__(self, in_channels, out_channels, n, bias, exclusive):\n",
    "        super(myLayer, self).__init__(in_channels * n, out_channels * n,\n",
    "                                            bias)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n = n\n",
    "        self.exclusive = exclusive\n",
    "\n",
    "        self.register_buffer('mask', torch.ones([self.n] * 2))\n",
    "        if self.exclusive:\n",
    "            self.mask = 1. - torch.triu(self.mask)\n",
    "        else:\n",
    "            self.mask = torch.tril(self.mask)\n",
    "        self.mask = torch.cat([self.mask] * in_channels, dim=1)\n",
    "        self.mask = torch.cat([self.mask] * out_channels, dim=0)\n",
    "        self.weight.data *= self.mask\n",
    "\n",
    "        # Correction to Xavier initialization\n",
    "        self.weight.data *= torch.sqrt(self.mask.numel() / self.mask.sum())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.functional.linear(x, self.mask * self.weight, self.bias)\n",
    "\n",
    "default_dtype_torch = torch.float64\n",
    "\n",
    "class bp_nn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n, bias, exclusive):\n",
    "        super(bp_nn, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n = n\n",
    "        self.epsilon = 1e-10\n",
    "        layers = []\n",
    "        layer1 = myLayer(in_channels, out_channels, n, bias, exclusive)\n",
    "        layers.append(layer1)\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        sample = torch.zeros(\n",
    "            [batch_size, 1, self.n])\n",
    "        for i in range(self.n):\n",
    "            x_hat = self.forward(sample)\n",
    "            #print(x_hat)\n",
    "            sample[:, :, i] = torch.bernoulli(\n",
    "                    x_hat[:, :, i]) * 2 - 1\n",
    "            \n",
    "        return sample, x_hat\n",
    "\n",
    "    def _log_prob(self, sample, x_hat):\n",
    "        mask = (sample + 1) / 2\n",
    "        log_prob = (torch.log(x_hat + self.epsilon) * mask +\n",
    "                    torch.log(1 - x_hat + self.epsilon) * (1 - mask))\n",
    "        log_prob = log_prob.view(log_prob.shape[0], -1).sum(dim=1)\n",
    "        return log_prob\n",
    "\n",
    "    def log_prob(self, sample):\n",
    "        x_hat = self.forward(sample)\n",
    "        log_prob = self._log_prob(sample, x_hat)\n",
    "        return log_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAAJiCAYAAAB6n55VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAE1RJREFUeJzt3c9rXtlhxvFHfS0hvU4ZKkop9VQxHk8ojmi9mD9hNu22UJqGUOTZ9MdmxrMNTExDGzDMKrQUaseLZt9VF0WbLtKVFim1Geh4jGrqRRYWJI3HqixVXdyZNplWv2zJ78P15wMC6/W9h7MSX859z7lz+/v7+wEAoNYvzHoCAAAcTrABAJQTbAAA5QQbAEA5wQYAUE6wAQCUE2wAAOUEGwBAOcEGAFBOsAEAlBNsAADlBBsAQDnBBgBQTrABAJQTbAAA5QQbAEA5wQYAUE6wAQCUE2wAAOUEGwBAOcEGAFBOsAEAlBNsAADlzs16AgAzsbubbG4m29vJ4mJy8WJyzp9EoJO/TsCr4/Hj5Pbt5HvfSz75JJmfTyaTZG8v2dlJLl9O1taSd95JlpdnPVuA/zG3v7+/P+tJAJypnZ3kxo3kww+Tubnk6dODr11aSvb3k+vXkw8+SBYWXt48AQ4g2IBxe/gwefvt5NGj5NNPj3/fdJpcuJCsrycrK2c3P4BjEGzAeD18mLz1VrK1NTz2PKnJZHg0urEh2oCZEmzAOO3sJKuryYMHzxdrn5tMkkuXknv3hu+8AcyAYz2AcbpxY3gM+iKxlgz3P3o0jAcwI1bYgPF5/Dh5/fXhyI7/x38m+ZMk60m2klxO8udJfvuwMRcXh3CzexSYAStswPjcvj3sBj3AbpJfT/KPSX6c5M+S/F6SzcPGnJtLbt06vTkCnIAVNmB8rlxJPvroRLf8ZpIPkvzuUePeu/cCEwN4PoINGJfd3eT8+WHTwTH9KMmXk/wwyW8cduHCQvLkiTciAC+dR6LAuGxunmg357MkX0/yhzki1pJh3M3N550ZwHMTbMC4bG8PR3Ecw38l+UaShSTfPc4Nk8mBGxkAzpJ1fWBcFhePdZTHfpJ3MjwO/fskx1qT29sbxgd4yXyHDRiXY36H7Y8yfGdtPcmXjju277ABM+KRKDAu584lb7xx6CX/luSvMwTbr2YIti8l+f5RY1++LNaAmRBswPisrSVLSwf+95czPBLdTvLTn/n5+mFjLi0N4wLMgEeiwPhsbSUXLpzuBgFvOgBmyAobMD7Ly8n168l0ejrjTafJ+++LNWBmrLAB47Szk6yuJg8evNgL4CeT5NKl4Q0HJzjfDeA0WWEDxmlhIVlfH1bFjnku2/8xmQz3r6+LNWCmBBswXisrycbGsEJ20sej0+lw38bGMA7ADAk2YNxWVpK7d5N33x02DhyyezTJEGqLi8l77w2PQcUaUMB32IBXx9ZWcutWcudOcv9+Mj+fHz95ktfOn0+ePRvOWVtbS65ds8EAqCLYgFfT7m6yuZnVN9/M3Y8/Ti5edCguUEuwAa+0ubm5+DMItPMdNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk24NW0u5vcv5+vJsn9+8PvAKUEG/DqePw4uXkzuXIlOX8+uXo1P0iSq1eT6XT4/ObNZGtr1jMF+Dlz+/v7+7OeBMCZ2tlJbtxIPvwwmZtLnj49+NqlpWR/P7l+Pfngg2Rh4eXNE+AAgg0Yt4cPk7ffTh49Sj799Pj3TafJhQvJ+nqysnJ28wM4BsEGjNfDh8lbbw2POPf2Tn7/ZJIsLycbG6INmCnBBozTzk6yupo8ePB8sfa5ySS5dCm5dy+Znz+9+QGcgE0HwDjduDE8Bn2RWEuG+x89GsYDmBErbMD4PH6cvP56sr194CXfTXInyb8k+dpn/z7U4uIQbsvLpzRJgOOzwgaMz+3bw27QQ/xakm8muXbcMefmklu3XnBiAM/HChswPleuJB99dKxLv5nk33OMFbbPx7137/nnBfCcrLAB47K7m3zyydmM7Y0IwIwINmBcNjfPbjfn/PwwPsBLJtiAcdneHo7iOAuTyaEbGQDOimADxmVx8cWP8jjI3t4wPsBLJtiAcbl4MXn27MjLdpNsJ9n77Gf7s88O9ezZMD7ASybYgHE5dy55440jL/t2kqUk30nyt5/9+9tH3XT58jA+wEsm2IDxWVtLlpYOveRbSfa/8POtw25YWhrGBZgB57AB47O1lVy4cLobBLzpAJghK2zA+CwvJ9evJ9Pp6Yw3nSbvvy/WgJmxwgaM085OsrqaPHjwYrtGJ5Pk0qXhDQdndb4bwBGssAHjtLCQrK8Pq2LPey7bZDLcv74u1oCZEmzAeK2sJBsbwwrZSR+PTqfDfRsbwzgAMyTYgHFbWUnu3k3efXfYOHDE7tFMp8N17703PAYVa0AB32EDXh1bW8mtW8mdO8OL3Ofn8+MnT/La+fPDobiXLw9Hd1y7ZoMBUEWwAa+m3d1kczOrb76Zux9/PLzBwKG4QCnBBrzS5ubm4s8g0M532AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYgFfT7m5y/36+miT37w+/A5QSbMCr4/Hj5ObN5MqV5Pz55OrV/CBJrl5NptPh85s3k62tWc8U4OfM7e/v7896EgBnamcnuXEj+fDDZG4uefr04GuXlpL9/eT69eSDD5KFhZc3T4ADCDZg3B4+TN5+O3n0KPn00+PfN50mFy4k6+vJysrZzQ/gGAQbMF4PHyZvvTU84tzbO/n9k0myvJxsbIg2YKYEGzBOOzvJ6mry4MHzxdrnJpPk0qXk3r1kfv705gdwAjYdAON048bwGPRFYi0Z7n/0aBgPYEassAHj8/hx8vrryfb2gZdsJXknyT8k+eUkf5HkDw4bc3FxCLfl5dOcKcCxWGEDxuf27WE36CH+NMlCkh8l+X6SP05y77Ab5uaSW7dOa4YAJ2KFDRifK1eSjz468L+fJPmlJHeTfOWzz76R5EKS7xw17r1Dsw7gTFhhA8Zldzf55JNDL/nXJJP8b6wlyW/liBW2xBsRgJkRbMC4bG4euZvzp0le+8JnryX5j6PGnp8fxgd4yQQbMC7b28NRHIf4UpKffOGznyT5xaPGnkwO3cgAcFYEGzAui4tHHuXxlSS7ST7+mc/+ORleBH+Yvb1hfICXzKYDYFx2d4cXu+/sHHrZ7yeZS/I3SX6Y5HeS/FOOiLaFheTJk+TcuVOaLMDxWGEDxuXcueSNN4687C+TPE3yK0m+luSvcowVtsuXxRowE4INGJ+1tWRp6dBLlpP8XYYjPh7miENzk2G8tbVTmR7ASXkkCozP1lZy4cLpbhDwpgNghqywAeOzvJxcv55Mp6cz3nSavP++WANmxgobME47O8nqavLgwYu9AH4ySS5dGt5wcMT5bgBnxQobME4LC8n6+rAqdsS5bAeaTIb719fFGjBTgg0Yr5WVZGNjWCE76ePR6XS4b2NjGAdghgQbMG4rK8ndu8m77w4bB47YPZrpdLjuvfeGx6BiDSjgO2zAq2NrK7l1K7lzZ3iR+/z88Nhzby959mw4Z21tLbl2zQYDoIpgA15Nu7vDi9y3t4cVtYsXHYoL1BJsAADlfIcNAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcoINAKCcYAMAKCfYAADKCTYAgHKCDQCgnGADACgn2AAAygk2AIBygg0AoJxgAwAoJ9gAAMoJNgCAcv8NRTWklirxClwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Degree = 2 # degree\n",
    "Height = 2 #Â Height of the tree\n",
    "N, J_interaction = graph_gen.tree_interaction(Degree,Height)\n",
    "j = graph_gen.fixed_value(2)\n",
    "J = graph_gen.set_J(J_interaction, j)\n",
    "h = 1.\n",
    "H = np.full((N,), h)\n",
    "tree = model.model(N, H, J, J_interaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = bp_nn(1,1,N,True, False)\n",
    "sample, x_hat = net.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters: 12\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "params = list(net.parameters())\n",
    "params = list(filter(lambda p: p.requires_grad, params))\n",
    "nparams = int(sum([np.prod(p.shape) for p in params]))\n",
    "print('Total number of trainable parameters: {}'.format(nparams))\n",
    "named_params = list(net.named_parameters())\n",
    "\n",
    "optimizer = torch.optim.SGD(params, lr=lr)\n",
    "optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1., -1., -1.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.]],\n",
       " \n",
       "         [[ 1., -1.,  1.]],\n",
       " \n",
       "         [[ 1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1.,  1.]],\n",
       " \n",
       "         [[-1.,  1.,  1.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.]],\n",
       " \n",
       "         [[-1.,  1., -1.]],\n",
       " \n",
       "         [[-1., -1.,  1.]],\n",
       " \n",
       "         [[-1., -1.,  1.]]], grad_fn=<CopySlices>),\n",
       " tensor([[[0.4145, 0.6806, 0.3871]],\n",
       " \n",
       "         [[0.5239, 0.4057, 0.6122]],\n",
       " \n",
       "         [[0.5239, 0.6780, 0.4002]],\n",
       " \n",
       "         [[0.5239, 0.6780, 0.4002]],\n",
       " \n",
       "         [[0.4145, 0.6806, 0.3871]],\n",
       " \n",
       "         [[0.4145, 0.4085, 0.5991]],\n",
       " \n",
       "         [[0.5239, 0.4057, 0.6122]],\n",
       " \n",
       "         [[0.4145, 0.4085, 0.5991]],\n",
       " \n",
       "         [[0.4145, 0.6806, 0.3871]],\n",
       " \n",
       "         [[0.4145, 0.6806, 0.3871]]], grad_fn=<SigmoidBackward>))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (100) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-a8b46a848ed3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta_init\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta_anneal\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menergy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0menergy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menergy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/pytorch_test/python_lib/model.py\u001b[0m in \u001b[0;36menergy\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         return (-0.5 * ((samples @ self.J_torch).view(m, 1, self.N) @ samples.view(\n\u001b[0;32m---> 82\u001b[0;31m             m, self.N, 1)).squeeze() - self.H_torch * torch.sum(samples, 1))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m#@jit(nopython=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (100) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "max_step = 1000\n",
    "beta_init = 1\n",
    "beta_anneal = 0\n",
    "step = 1\n",
    "batch_size = 100\n",
    "for step in range(0, max_step + 1):\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            sample, x_hat = net.sample(batch_size)\n",
    "        assert not sample.requires_grad\n",
    "        assert not x_hat.requires_grad\n",
    "\n",
    "        log_prob = net.log_prob(sample)\n",
    "        beta = beta_init * (1 - beta_anneal**step)\n",
    "        with torch.no_grad():\n",
    "            energy = tree.energy(sample.double())\n",
    "            loss = log_prob + beta * energy\n",
    "        assert not energy.requires_grad\n",
    "        assert not loss.requires_grad\n",
    "        loss_reinforce = torch.mean((loss - loss.mean()) * log_prob)\n",
    "        loss_reinforce.backward()\n",
    "\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0794,  0.0000,  0.0000],\n",
       "        [ 0.3742, -0.4221,  0.0000],\n",
       "        [-0.5356,  0.6621,  0.6466]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoreg.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3114, -1.0834,  0.1316], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([0,1,0])\n",
    "autoreg.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "layers.append(autoreg)\n",
    "layers.append(nn.Sigmoid())\n",
    "net = nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3964, 0.4787, 0.5913], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-22-b6672e7dcdf1>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-b6672e7dcdf1>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    nn.functional.linear(\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "x = [0,0,1]\n",
    "nn.functional.linear("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "Parameter containing:\n",
      "tensor([[-0.1123, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
      "          0.0000, -0.0000],\n",
      "        [-0.0000, -0.2625, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "         -0.0000, -0.0000],\n",
      "        [ 0.0000,  0.0000,  0.1749,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
      "         -0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  0.2426,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "         -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  0.0000,  0.2974,  0.0000, -0.0000, -0.0000,\n",
      "          0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.2120, -0.0000, -0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2698,  0.0000,\n",
      "         -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.1888,\n",
      "         -0.0000, -0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "          0.1582, -0.0000],\n",
      "        [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
      "         -0.0000,  0.3089]], requires_grad=True)\n",
      "tensor([[-0.3552, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -0.0000,\n",
      "          0.0000, -0.0000],\n",
      "        [-0.0000, -0.8300, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "         -0.0000, -0.0000],\n",
      "        [ 0.0000,  0.0000,  0.5532,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,\n",
      "         -0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  0.7671,  0.0000,  0.0000,  0.0000, -0.0000,\n",
      "         -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  0.0000,  0.9405,  0.0000, -0.0000, -0.0000,\n",
      "          0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.6704, -0.0000, -0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.8532,  0.0000,\n",
      "         -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.5970,\n",
      "         -0.0000, -0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "          0.5003, -0.0000],\n",
      "        [ 0.0000, -0.0000,  0.0000, -0.0000,  0.0000, -0.0000, -0.0000,  0.0000,\n",
      "         -0.0000,  0.9767]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChannelLinear(in_features=10, out_features=10, bias=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChannelLinear(1,1,10,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "nn.Linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
